{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  \n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('COMPRESSED_CIS_tle_data.parquet')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describe the fields:**\n",
    "\n",
    "0. idElset: A unique identifier for each satellite element set. Object data type.\n",
    "\n",
    "1. classificationMarking: Indicates the classification of the satellite data, where \"U\" stands for unclassified. Object data type.\n",
    "\n",
    "2. satNo: The satellite number, a unique identifier for a satellite. Interger data type.\n",
    "\n",
    "3. epoch: The timestamp indicating when the satellite's position and orbital elements were recorded. This is in UTC format. Currently as object data type.\n",
    "\n",
    "4. meanMotion: The number of revolutions the satellite completes around the earth per day. This parameter gives an idea of the speed at which the satellite orbits the earth. 64-bit floating-point number.\n",
    "\n",
    "5. idOnOrbit: A repeat of the satellite number (satNo), possibly for consistency across different data sources. Object data type.\n",
    "\n",
    "6. eccentricity: A measure of how much the satellite's orbit deviates from a perfect circle. Values closer to 0 indicate a more circular orbit, while values closer to 1 indicate a more elliptical orbit. 64-bit floating-point number.\n",
    "\n",
    "7. inclination: The angle between the satellite's orbital plane and the Earth's equator, measured in degrees. It indicates how far north or south the satellite travels relative to the equator. 64-bit floating-point number.\n",
    "\n",
    "8. raan (Right Ascension of the Ascending Node): The angle, measured from a fixed point in the sky, representing where the satellite crosses the equator from the southern hemisphere to the northern hemisphere. 64-bit floating-point number.\n",
    "\n",
    "9. argOfPerigee (Argument of Perigee): The angle within the satellite's orbital plane that defines the point where the satellite is closest to the Earth (perigee). 64-bit floating-point number.\n",
    "\n",
    "10. meanAnomaly: An angular parameter that helps describe the position of the satellite along its orbit at a specific time. 64-bit floating-point number.\n",
    "\n",
    "11. revNo: The revolution number of the satellite, indicating the number of complete orbits made by the satellite since launch. An interger data type.\n",
    "\n",
    "12. bStar: A drag term used in the satellite's orbital model to account for atmospheric drag affecting the satellite’s motion, particularly in lower orbits. 64-bit floating-point number.\n",
    "\n",
    "13. meanMotionDot: The first derivative of the mean motion, representing how the satellite’s speed is changing over time, which might be due to perturbing forces like gravitational effects. 64-bit floating-point number.\n",
    "\n",
    "14. meanMotionDDot: The second derivative of the mean motion, further describing changes in the satellite’s speed, providing more detailed information about the satellite's acceleration or deceleration. 64-bit floating-point number.\n",
    "\n",
    "15. semiMajorAxis: The distance from the center of the satellite's orbit to its farthest point, measured in kilometers. This value is important for describing the size of the satellite's orbit. 64-bit floating-point number.\n",
    "\n",
    "16. period: The time it takes for the satellite to complete one full orbit around the Earth, measured in minutes. 64-bit floating-point number.\n",
    "\n",
    "17. apogee: The highest point in the satellite's orbit, i.e., the farthest distance from the Earth during its orbit. 64-bit floating-point number.\n",
    "\n",
    "18. perigee: The lowest point in the satellite's orbit, i.e., the closest distance to the Earth during its orbit. 64-bit floating-point number.\n",
    "\n",
    "19. line1: A string representing the first line of a Two-Line Element (TLE) format, which contains information about the satellite's orbit. Object data type.\n",
    "\n",
    "20. line2: A string representing the second line of a TLE format, which includes additional details about the satellite's orbital elements. Object data type.\n",
    "\n",
    "21. createdAt: The timestamp indicating when this specific record or data entry was created. Object data type.\n",
    "\n",
    "22. createdBy: The identifier for the system or person responsible for generating this specific record. Object data type.\n",
    "\n",
    "23. source: The organization or system that provided the satellite data. In this case, \"18th SPCS\" refers to the 18th Space Control Squadron, which tracks space objects. Object data type.\n",
    "\n",
    "24. dataMode: Describes the type or mode of data being used or collected. For example, 'REAL' might indicate real-time or current data. Object data type.\n",
    "\n",
    "25. origNetwork: Likely identifies the network or system through which the data was originally collected or processed. Object data type.\n",
    "\n",
    "26. algorithm: The algorithm used to process or analyze the satellite data. In this case, 'SGP4' refers to the Simplified General Perturbations model, which is a commonly used orbital model for predicting satellite positions. Object data type.\n",
    "\n",
    "27. sourceDL: Possibly refers to additional details or metadata about the data source, though it’s marked as None in the provided example. Object data type.\n",
    "\n",
    "28. ephemType: Likely refers to the type of ephemeris (data that provides the positions of astronomical objects), though it is marked as NaN in this example. 64-bit floating-point number. \n",
    "\n",
    "29. uct: May refer to Universal Coordinated Time (UTC), though this column is marked as None in the example provided. Object data type.\n",
    "\n",
    "30. descriptor: Additional descriptive information about the satellite or data, though it is marked as None in this case. Object data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIS_satcat.pkl dataset\n",
    "file_path = r'C:\\Users\\megan\\OneDrive\\Desktop\\Data_Analytics\\CIS 831A\\Project\\CIS831_russat-main\\output\\CIS_satcat.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    satcat = pickle.load(f)\n",
    "\n",
    "# Convert the satcat data into a DataFrame for easy manipulation\n",
    "satcat_df = pd.DataFrame(satcat)\n",
    "\n",
    "# Ensure 'NORAD_CAT_ID' and 'satNo' are the same type, converting both to integers\n",
    "satcat_df['NORAD_CAT_ID'] = satcat_df['NORAD_CAT_ID'].astype(int)\n",
    "df['satNo'] = df['satNo'].astype(int)\n",
    "\n",
    "# Merge the original dataset with the new data on 'satNo' and 'NORAD_CAT_ID'\n",
    "# Keep only the 'COUNTRY' and 'OBJECT_TYPE' field from the new data\n",
    "enriched_df = pd.merge(df, satcat_df[['NORAD_CAT_ID', 'COUNTRY', 'OBJECT_TYPE']], \n",
    "                       how='inner', left_on='satNo', right_on='NORAD_CAT_ID')\n",
    "\n",
    "# Filter to include only 'CIS' country and 'ROCKET BODY' or 'PAYLOAD'\n",
    "filtered_df = enriched_df[(enriched_df['COUNTRY'] == 'CIS') & \n",
    "                          (enriched_df['OBJECT_TYPE'].isin(['PAYLOAD']))]\n",
    "\n",
    "# Apply the orbital features filter to select only the relevant columns\n",
    "orbital_features = [\n",
    "    'epoch', 'meanMotion', 'eccentricity', 'inclination', \n",
    "    'raan', 'argOfPerigee', 'meanAnomaly', 'meanMotionDot', \n",
    "    'meanMotionDDot', 'semiMajorAxis', 'apogee', 'perigee'\n",
    "]\n",
    "\n",
    "# Add the necessary columns for identification (e.g., 'satNo', 'COUNTRY', 'OBJECT_TYPE')\n",
    "necessary_columns = ['satNo', 'COUNTRY', 'OBJECT_TYPE'] + orbital_features\n",
    "\n",
    "# Filter the DataFrame to keep only the necessary columns\n",
    "filtered_df = filtered_df[necessary_columns]\n",
    "\n",
    "# Drop Duplications\n",
    "filtered_df = filtered_df.drop_duplicates()\n",
    "\n",
    "# Display the filtered data to ensure it worked\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method:**\n",
    "\n",
    "This example is designed to detect and visualize anomalies in satellite orbital data, focus on rates of change for two key orbital features: Semi-Major Axis and Inclination. It identifies significant deviations in these features as potential indicators of satellite maneuvers, then visualizes and counts anomalies over time. Dure the previous step, I limited the data to just Russian Payload data.\n",
    "\n",
    "1. Data Preprocessing: Satellite data, grouped by satellite ID, is preprocessed by converting the time feature (epoch) to UTC and calculating the rate of change for the orbital features: Semi-Major Axis and Inclination.\n",
    "\n",
    "2. Anomaly Detection: Thresholds are set for each feature to detect significant changes, which may indicate intentional satellite movement. These thresholds are 10 for the Semi-Major Axis and 0.1 for Inclination. Points exceeding these thresholds are classified as anomalies.\n",
    "\n",
    "3. Normalization: To standardize the values for Semi-Major Axis and Inclination across different satellites, the data is normalized using StandardScaler to allow for fair comparisons of orbital changes across different satellites.\n",
    "\n",
    "4. Anomaly Visualization: For each satellite, the anomalies are visualized in a time series plot where significant deviations are highlighted. This helps in understanding if the detected changes are potentially intentional.\n",
    "\n",
    "5. Interactive Aggregation: Anomalies are aggregated by day and visualized interactively using Plotly, allowing zooming capabilities for more focused analysis of specific time ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate the rate of change for a given feature\n",
    "def calculate_rate_of_change(sat_group, feature, time_column='epoch'):\n",
    "    delta_feature = sat_group[feature].diff().abs()\n",
    "    delta_time = sat_group[time_column].diff().dt.total_seconds() / (3600 * 24)  # convert time difference to days\n",
    "    rate_of_change = delta_feature / delta_time\n",
    "    return rate_of_change\n",
    "\n",
    "# Set thresholds for significant changes in Semi-Major Axis and Inclination\n",
    "semi_major_axis_threshold = 10  # Adjust this based on your dataset (e.g., large maneuvers)\n",
    "inclination_threshold = 0.1      # Example threshold for inclination change\n",
    "\n",
    "# Group the data by satellite\n",
    "grouped = filtered_df.groupby('satNo')\n",
    "\n",
    "# List to store anomalies\n",
    "all_anomalies = []\n",
    "\n",
    "# Create a scaler to normalize the values\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for sat_no, sat_group in grouped:\n",
    "    print(f\"Processing satellite {sat_no}\")\n",
    "    \n",
    "    # Convert 'epoch' to datetime if not already done\n",
    "    sat_group['epoch'] = pd.to_datetime(sat_group['epoch'], errors='coerce')\n",
    "    \n",
    "    # Drop rows with invalid 'epoch' values (if any)\n",
    "    sat_group = sat_group.dropna(subset=['epoch'])\n",
    "    \n",
    "    # Sort by 'epoch' to maintain time order\n",
    "    sat_group = sat_group.sort_values('epoch')\n",
    "\n",
    "    # Ensure the 'epoch' column is in UTC (if not already)\n",
    "    if sat_group['epoch'].dt.tz is None:\n",
    "        sat_group['epoch'] = sat_group['epoch'].dt.tz_localize('UTC')\n",
    "\n",
    "    # Calculate rate of change for Semi-Major Axis and Inclination\n",
    "    sat_group['semi_major_axis_rate_of_change'] = calculate_rate_of_change(sat_group, 'semiMajorAxis')\n",
    "    sat_group['inclination_rate_of_change'] = calculate_rate_of_change(sat_group, 'inclination')\n",
    "\n",
    "    # Normalize both Semi-Major Axis and Inclination for standardized scale\n",
    "    sat_group[['semiMajorAxis', 'inclination']] = scaler.fit_transform(sat_group[['semiMajorAxis', 'inclination']])\n",
    "\n",
    "    # Identify points with significant changes\n",
    "    anomalies = sat_group[(sat_group['semi_major_axis_rate_of_change'] > semi_major_axis_threshold) |\n",
    "                          (sat_group['inclination_rate_of_change'] > inclination_threshold)]\n",
    "\n",
    "    if not anomalies.empty:\n",
    "        # Store anomalies for this satellite for the final summary plot\n",
    "        all_anomalies.append(anomalies)\n",
    "\n",
    "        # Get OBJECT_TYPE for the current satellite\n",
    "        object_type = sat_group['OBJECT_TYPE'].iloc[0]  # Assuming 'OBJECT_TYPE' is consistent per satellite\n",
    "\n",
    "        # Visualize the anomalies for this satellite with OBJECT_TYPE in the title\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(sat_group['epoch'], sat_group['semiMajorAxis'], label='Semi-Major Axis', color='blue')\n",
    "        plt.plot(sat_group['epoch'], sat_group['inclination'], label='Inclination', color='orange')\n",
    "        plt.scatter(anomalies['epoch'], anomalies['semiMajorAxis'], color='red', label='Anomalous Semi-Major Axis', marker='x')\n",
    "        plt.scatter(anomalies['epoch'], anomalies['inclination'], color='green', label='Anomalous Inclination', marker='o')\n",
    "        plt.xlabel('Epoch (UTC)')\n",
    "        plt.ylabel('Standardized Orbital Parameters')\n",
    "        plt.title(f\"Anomalies for Satellite {sat_no} ({object_type}) - Potential Maneuvers\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Step 3: Combine all anomalies\n",
    "combined_anomalies = pd.concat(all_anomalies)\n",
    "\n",
    "# Step 4: Separate anomalies by OBJECT_TYPE\n",
    "rocket_bodies = combined_anomalies[combined_anomalies['OBJECT_TYPE'] == 'ROCKET BODY']\n",
    "payloads = combined_anomalies[combined_anomalies['OBJECT_TYPE'] == 'PAYLOAD']\n",
    "\n",
    "# Count the number of anomalies per epoch for each type\n",
    "anomalies_per_epoch_rocket_bodies = rocket_bodies.groupby('epoch').size().reset_index(name='anomaly_count')\n",
    "anomalies_per_epoch_payloads = payloads.groupby('epoch').size().reset_index(name='anomaly_count')\n",
    "\n",
    "# Step 5: Create Plotly figure to plot the count of anomalies over time (epoch)\n",
    "# Group anomalies by day\n",
    "combined_anomalies['epoch_day'] = combined_anomalies['epoch'].dt.floor('D')  # Group by day\n",
    "anomalies_per_day = combined_anomalies.groupby('epoch_day').size().reset_index(name='anomaly_count')\n",
    "\n",
    "# Create a zoomable plot using Plotly\n",
    "fig = px.line(anomalies_per_day, x='epoch_day', y='anomaly_count', title='Anomaly Count Over Time (Grouped by Day)',\n",
    "              labels={'epoch_day': 'Date (UTC)', 'anomaly_count': 'Anomaly Count'},\n",
    "              markers=True)\n",
    "\n",
    "# Add zoom capability\n",
    "fig.update_xaxes(rangeslider_visible=True)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Print the total number of anomalies detected\n",
    "print(f\"Total anomalies detected: {combined_anomalies.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTICS (Ordering Points To Identify the Clustering Structure)\n",
    "\n",
    "Density-based Clustering: OPTICS is particularly good at identifying clusters of varying densities, which is useful in scenarios where some satellite movements might follow tight, controlled patterns while others might have larger deviations (possibly intentional).\n",
    "\n",
    "Hierarchical Clustering: Unlike DBSCAN, OPTICS allows for the creation of hierarchical clusters, which can help in identifying outliers that don't belong to any cluster and track shifts in movement patterns more accurately.\n",
    "\n",
    "No Need to Specify Cluster Count: Similar to DBSCAN, you don’t need to pre-define the number of clusters. This can be useful when analyzing satellite data, where the number of clusters (potential movement patterns or anomalies) isn’t always known.\n",
    "\n",
    "Detection of Both Anomalous Clusters and Points: OPTICS provides a reachability plot that can highlight outliers that don't belong to any particular cluster, making it ideal for detecting satellites with potential intentional movement.\n",
    "\n",
    "**Methodology:**\n",
    "\n",
    "1. Custom Silhouette Scorer for OPTICS: The code begins by defining a custom scoring function, optics_silhouette_scorer. This function applies the Silhouette Score to measure the quality of clusters generated by OPTICS, a clustering algorithm. If there is only one cluster (i.e., no meaningful clustering), the function returns a low score (-1), ensuring that the model will prefer configurations that produce more than one cluster.\n",
    "\n",
    "2. Hyperparameter Tuning: The RandomizedSearchCV method is used to perform hyperparameter tuning for the OPTICS model. It randomly samples from predefined hyperparameter values (min_samples and max_eps), which control the minimum number of samples for a core point and the maximum distance between points in the same cluster, respectively. The tuning process evaluates 10 combinations of these parameters, and the custom silhouette scorer helps identify the best combination of hyperparameters that produces well-separated clusters.\n",
    "\n",
    "3. Satellite Data Preprocessing: Each satellite group is processed separately. Data preprocessing steps include:\n",
    "    - Datetime conversion: The 'epoch' column is converted to a datetime format.\n",
    "    - Sorting and timezone localization: The data is sorted by time, and the 'epoch' is localized to UTC if needed.\n",
    "    - Imputation of missing values: Missing values in the key features (semiMajorAxis and inclination) are filled using the mean imputation strategy.\n",
    "    - Normalization: The orbital parameters are scaled to a standardized range using StandardScaler.\n",
    "\n",
    "4. Rate of Change Calculation: The rate of change for key orbital parameters (semi-major axis and inclination) is calculated to capture significant variations over time, which might indicate satellite maneuvers.\n",
    "\n",
    "5. OPTICS Anomaly Detection: For each satellite, after preprocessing, the OPTICS algorithm is applied to detect clusters and outliers. The best configuration of hyperparameters (found using RandomizedSearchCV) is used to fit the data. The OPTICS labels are extracted, with outliers (labeled as -1) indicating anomalous points in the satellite's trajectory.\n",
    "\n",
    "6. Anomaly Visualization: For each satellite with detected anomalies, the orbital features (semi-major axis and inclination) are plotted over time, and anomalies are highlighted with different markers on the plots. Each plot is titled with the satellite number and object type.\n",
    "\n",
    "7. Summary and Final Plot: The anomalies detected across all satellites are combined, and a final Plotly visualization is created. The plot shows the anomaly count over time, grouped by day, to provide a time-based trend of detected satellite anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a custom scoring function for OPTICS using silhouette score\n",
    "def optics_silhouette_scorer(estimator, X):\n",
    "    labels = estimator.fit_predict(X)\n",
    "    if len(set(labels)) > 1:\n",
    "        return silhouette_score(X, labels)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# Define the hyperparameter space for OPTICS\n",
    "param_distributions = {\n",
    "    'min_samples': [5, 10, 25, 50],\n",
    "    'max_eps': [0.5, 1.0, 1.5, 2.0]\n",
    "}\n",
    "\n",
    "# Process each satellite\n",
    "for sat_no, sat_group in grouped:\n",
    "    print(f\"Processing satellite {sat_no}\")\n",
    "    \n",
    "    sat_group['epoch'] = pd.to_datetime(sat_group['epoch'], errors='coerce')\n",
    "    sat_group = sat_group.dropna(subset=['epoch']).sort_values('epoch')\n",
    "    \n",
    "    if sat_group['epoch'].dt.tz is None:\n",
    "        sat_group['epoch'] = sat_group['epoch'].dt.tz_localize('UTC')\n",
    "\n",
    "    # Imputation and scaling\n",
    "    sat_group[['semiMajorAxis', 'inclination']] = imputer.fit_transform(sat_group[['semiMajorAxis', 'inclination']])\n",
    "    sat_group[['semiMajorAxis', 'inclination']] = scaler.fit_transform(sat_group[['semiMajorAxis', 'inclination']])\n",
    "\n",
    "    # Select features for clustering\n",
    "    features_to_cluster = sat_group[['semiMajorAxis', 'inclination']].values\n",
    "\n",
    "    if len(features_to_cluster) > 1:\n",
    "        # For satellites with more than 1 sample, use KFold or RandomizedSearchCV\n",
    "        optics_model = OPTICS()\n",
    "        \n",
    "        # Adjust cross-validation based on the number of samples\n",
    "        if len(features_to_cluster) >= 5:\n",
    "            cv = KFold(n_splits=5)\n",
    "        else:\n",
    "            cv = LeaveOneOut()  # For small datasets\n",
    "        \n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=optics_model,\n",
    "            param_distributions=param_distributions,\n",
    "            n_iter=10,\n",
    "            random_state=42,\n",
    "            scoring=optics_silhouette_scorer,\n",
    "            cv=cv\n",
    "        )\n",
    "        \n",
    "        random_search.fit(features_to_cluster)\n",
    "        best_model = random_search.best_estimator_\n",
    "    else:\n",
    "        print(f\"Skipping satellite {sat_no} due to insufficient data.\")\n",
    "        continue\n",
    "    \n",
    "    # Apply the best model\n",
    "    best_model.fit(features_to_cluster)\n",
    "    sat_group['optics_label'] = best_model.labels_\n",
    "    \n",
    "    # Identify anomalies\n",
    "    anomalies = sat_group[sat_group['optics_label'] == -1]\n",
    "    \n",
    "    if not anomalies.empty:\n",
    "        all_anomalies.append(anomalies)\n",
    "\n",
    "        object_type = sat_group['OBJECT_TYPE'].iloc[0]\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(sat_group['epoch'], sat_group['semiMajorAxis'], label='Semi-Major Axis', color='blue')\n",
    "        plt.plot(sat_group['epoch'], sat_group['inclination'], label='Inclination', color='orange')\n",
    "        plt.scatter(anomalies['epoch'], anomalies['semiMajorAxis'], color='red', marker='x', label='Anomalous Semi-Major Axis')\n",
    "        plt.scatter(anomalies['epoch'], anomalies['inclination'], color='green', marker='o', label='Anomalous Inclination')\n",
    "        plt.xlabel('Epoch (UTC)')\n",
    "        plt.ylabel('Standardized Orbital Parameters')\n",
    "        plt.title(f\"Anomalies for Satellite {sat_no} ({object_type}) - Potential Maneuvers\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "#Removed consolidated plot for overall activity, rather do something different following this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Actions to add...\n",
    "\n",
    "0. Explain adding another feature such as mean_motion\n",
    "1. Label the anomalies back on the orginal data set\n",
    "2. Plot consolidated activity windows based on anomalies detected\n",
    "3. Plot over map physical location the during the anomaly windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired T-Test Comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
